\chapter*{Introduction}
\phantomsection{}
\addcontentsline{toc}{chapter}{Introduction}

Optimal transport is the theory of moving a mass onto another mass whilst minimizing the incurring costs associated with the underlying transportation. Over the years different formulations have been posed, all related to each other. With the advance of computing technology implementations that are based on optimal transport have entered application in various ways. One challenge this sets is the incorporation of large-scale problems, as previous algorithms do not scale well with increasing dimension. In this thesis we will outline one particular approach for solving large-scale optimal transport.

The first optimal transport problem was posed in 1781 by Gaspard Monge\ \cite{Mon1781}. Considering a cost function $c$, its modern formulation for two probability measures $\mu$ and $\nu$ is
\[ \inf \left\{ \int\limits_X c(x, T(x))~\Dx{\mu} : T \in \MF{X}{Y}, \push{\mu} = \nu \right\}. \]
It suffers from the problem of not allowing mass splitting, limiting its usage. In 1942 Leonid Kantorovich\ \cite{Kan1942} put forward a relaxed form of the original problem, allowing for the application of primal-dual optimization theory. Instead of directly optimizing over \textit{transport maps} between two spaces, the objective now takes a joint measure, which attains the starting measures as its marginals, and assing a cost to the \textit{transport plan} by integrating the underlying cost function with respect to it:
\[ \inf \left\{ \int\limits_{X \times Y} c(x, y)~\Dx[x, y]{\gamma} : \gamma \in \TP{\mu}{\nu} \right\}. \]
Recently, optimal transport has been used to advance areas of applied mathematics like machine learning, image processing and auction processes. In these applications it is often unpractical to calculate an exact solution to the optimal transport problem, instead an approximated solution is used. The main tool for this is the so-called \textit{Sinkhorm algorithm}, which iteratively improves dual variables. As it is focused on a small-scale problem formulation,\ \cite{Gene2016} and\ \cite{Arjo2017} proposed methods to expand the application of optimal transport to samples of larger dimensions, acheiving at least linear operations per iteration. Building on this work,\ \cite{Seg2018} have applied a stochastic gradient descent method to describe an approach that works well with large-scale problems, reducing to a constant number of operations per iteration. The estimation of optimal transport maps and plans using their proposed method is the main objective, which we wish to pursue.

This thesis consists of two main parts. The first part will function as a general introduction to optimal transport and provide related results, following\ \cite{San2015}, Chapter~1, closely. Section~\ref{TheMonProb} states the Monge formulation of optimal transport and points out two issues arising from it. Section~\ref{KantRelax} introduces the Kantorovich relaxation and gives results about the feasibility of the problem. In Section~\ref{KanDual} duality theory is used to derive a dual problem, give conditions on the existence of a dual solution, and outline presumptions necessary for strong duality to hold. The second part will build on the theory layed out and introduce estimations for solutions of the optimal transport problem as given by\ \cite{Seg2018}. To acheive this, Section~\ref{RegOT} introduces regularization of the original transport problem, and Section~\ref{RegDualBaryProj} gives tools to apply duality theory as well as obtain transport maps from transport plans. The Sinkhorn algorithm is then used as a starting point to expand onto the estimation of optimal transport plans and maps in Section~\ref{StoPlanAndMapEst}. We will provide references to a number of applications in theoretical and applied mathematics in at the end. Appendix~\ref{appendix} will provide useful theorems, the proofs of which can be found in the accompanying references.