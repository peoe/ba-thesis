\chapter*{Introduction}
\phantomsection{}
\addcontentsline{toc}{chapter}{Introduction}

Optimal transport is the theory of moving a unit of mass whilst minimizing the incurring costs associated with the underlying transportation. Over the years different formulations have been posed, all related to each other. With the advance of computing technology, implementations that are based on optimal transport have entered application in various ways. One challenge this sets is the incorporation of large-scale problems, as previous algorithms do not scale well with increasing dimension. In this thesis one particular approach for solving large-scale optimal transport will be outlined.

The first optimal transport problem was posed in 1781 by Gaspard Monge\ \cite{Mon1781}. Considering a cost function $\map[c]{X \times Y}{\RZero \ cup \{ \infty \}}$, its modern formulation for two probability measures $\mu \in \PM{X}$ and $\nu \in \PM{Y}$ is
\[ \inf \left\{ \int\limits_X c(x, T(x))~\Dx{\mu} : T \in \MF{X}{Y}, \push{\mu} = \nu \right\}, \]
where \MF{X}{Y} is the set of all measurable functions from $X$ to $Y$, and \push{\mu} describes the push-forward of $\mu$ under some $T$.
It suffers from the problem of not allowing mass splitting, limiting its usage. In 1942, Leonid Kantorovich\ \cite{Kan1942} put forward a relaxed form of the original problem, allowing for the application of primal-dual optimization theory. Instead of directly optimizing over \textit{transport maps} between two spaces, the objective now takes a joint measure, which attains the starting measures as its marginals, and assing a cost to the \textit{transport plan} by integrating the underlying cost function with respect to it:
\[ \inf \left\{ \int\limits_{X \times Y} c(x, y)~\Dx[x, y]{\gamma} : \gamma \in \TP{\mu}{\nu} \right\}. \]
Here, \TP{\mu}{\nu} is the set of all joint measures on $X \times Y$ that have $\mu$ and $\nu$ as marginals. To aid in the approximation of optimal transport, entropic regularization may be performed, resulting in
\[ \inf \left\{ \int\limits_{X \times Y} c~\D[\gamma] + \int\limits_{X \times Y} \gamma(x, y) \big( \log(\gamma(x, y)) - 1 \big)~\D[(x, y)] : \gamma \in \TP{\mu}{\nu} \right\}. \]

Recently, optimal transport has been used to advance areas of applied mathematics like machine learning, image processing and auction processes. In these applications it is often unpractical to calculate an exact solution to the optimal transport problem, instead an approximated solution is used. The main tool for this is the so-called \textit{Sinkhorm algorithm}, which iteratively improves dual variables of the transport problem and solves the entropically regularized transport problem. A near-liner time approximation of this algorithm has been acheived by\ \cite{Alts2019}. In contrast to this traditional approach,\ \cite{Gene2016} proposed methods to expand the application of optimal transport approximation to samples of large scales, by using stochastic optimization. Building on this work,\ \cite{Seg2018} have applied a stochastic gradient descent method to describe an approach that works well with large-scale problems. They reduced the complexity to a constant cost by training neural networks on samples of fixed size to estimate an optimal transport plan, and approximate an optimal transport map from the plan via the \textit{barycentric projection}. In particular, this approach lends itself to the handling of continuous problems, in contrast to previous restrictions on discrete formulations of regularized transport, see e.g.\ \cite{Ferra2013}. The estimation of optimal transport plans and maps using this method is the main objective described here.

This thesis consists of two main parts. The first part will function as a general introduction to optimal transport and provide related results. Section~\ref{TheMonProb} states the Monge formulation of optimal transport, Section~\ref{KantRelax} introduces the Kantorovich relaxation and gives results about the feasibility of the relaxed problem. In Section~\ref{KanDual} duality theory is used to derive a dual problem, give conditions on the existence of a dual solution, and outline presumptions necessary for strong duality to hold.

The second part will build upon the given theory and introduce methods of estimating solutions of the optimal transport problem as given by\ \cite{Seg2018}. To achieve this, Section~\ref{RegOT} introduces regularization of the original transport problem, Section~\ref{BaryProj} gives a tool to obtain transport maps from transport plans, and Section~\ref{RegDual} uses duality theory to derive the Sinkhorn algorithm. This algorithm is then used as a starting point to expand onto the estimation of optimal transport plans and maps via stochastic gradient descent in Section~\ref{StoPlanAndMapEst}. References to a number of applications in theoretical and applied mathematics will be provided at the end.