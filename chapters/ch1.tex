\chapter*{Introduction}
\phantomsection{}
\addcontentsline{toc}{chapter}{Introduction}

Optimal transport is the theory of moving a unit of mass onto another mass whilst minimizing the incurring costs associated with the underlying transportation. Over the years different formulations have been posed, all related to each other. With the advance of computing technology, implementations that are based on optimal transport have entered application in various ways. One challenge this sets is the incorporation of large-scale problems, as previous algorithms do not scale well with increasing dimension. In this thesis one particular approach for solving large-scale optimal transport will be outlined.

The first optimal transport problem was posed in 1781 by Gaspard Monge\ \cite{Mon1781}. Considering a cost function $\map[c]{X \times Y}{\RZero \ cup \{ \infty \}}$, its modern formulation for two probability measures $\mu \in \PM{X}$ and $\nu \in \PM{Y}$ is
\[ \inf \left\{ \int\limits_X c(x, T(x))~\Dx{\mu} : T \in \MF{X}{Y}, \push{\mu} = \nu \right\}, \]
where \MF{X}{Y} is the set of all measurable functions from $X$ to $Y$, and \push{\mu} describes the push-forward of $\mu$ under some $T$.
It suffers from the problem of not allowing mass splitting, limiting its usage. In 1942, Leonid Kantorovich\ \cite{Kan1942} put forward a relaxed form of the original problem, allowing for the application of primal-dual optimization theory. Instead of directly optimizing over \textit{transport maps} between two spaces, the objective now takes a joint measure, which attains the starting measures as its marginals, and assing a cost to the \textit{transport plan} by integrating the underlying cost function with respect to it:
\[ \inf \left\{ \int\limits_{X \times Y} c(x, y)~\Dx[x, y]{\gamma} : \gamma \in \TP{\mu}{\nu} \right\}. \]
Here, \TP{\mu}{\nu} is the set of all joint measures on $X \times Y$ that have $\mu$ and $\nu$ as marginals. To aid in the approximation of optimal transport, entropic regularization may be performed, resulting in
\[ \inf \left\{ \int\limits_{X \times Y} c~\D[\gamma] + \int\limits_{X \times Y} \gamma(x, y) \big( \log(\gamma(x, y)) - 1 \big)~\D[(x, y)] : \gamma \in \TP{\mu}{\nu} \right\}. \]

\todoinline{TODO:~add reference to\ \cite{ferra2013} for reg disc OT}
Recently, optimal transport has been used to advance areas of applied mathematics like machine learning, image processing and auction processes. In these applications it is often unpractical to calculate an exact solution to the optimal transport problem, instead an approximated solution is used. The main tool for this is the so-called \textit{Sinkhorm algorithm}, which iteratively improves dual variables of the transport problem and solves the entropically regularized problem. A near-liner time approximation of this algorithm has been acheived by\ \cite{Alts2019}. However, because its complexity only allows for efficient solving of problems involving small dimensions,\ \cite{Gene2016} and\ \cite{Arjo2017} proposed methods to expand the application of optimal transport approximation to samples of larger dimensions, achieving at least linear complexity. Building on this work,\ \cite{Seg2018} have applied a stochastic gradient descent method to describe an approach that works well with large-scale problems. Reducing the complexity to a constant complexity per iteration by training neural networks on samples of constant size. The estimation of optimal transport plans and maps using their proposed method is the main objective described here.

This thesis consists of two main parts. The first part will function as a general introduction to optimal transport and provide related results, following\ \cite{San2015}, Chapter~1, closely. Section~\ref{TheMonProb} states the Monge formulation of optimal transport and points out two issues arising from it. Section~\ref{KantRelax} introduces the Kantorovich relaxation and gives results about the feasibility of the relaxed problem. In Section~\ref{KanDual} duality theory is used to derive a dual problem, give conditions on the existence of a dual solution, and outline presumptions necessary for strong duality to hold. The second part will build upon the given theory and introduce methods of estimating solutions of the optimal transport problem as given by\ \cite{Seg2018}. To achieve this, Section~\ref{RegOT} introduces regularization of the original transport problem, Section~\ref{BaryProj} gives a tool to obtain transport maps from transport plans, and Section~\ref{RegDual} uses duality theory to derive the Sinkhorn algorithm. This algorithm is then used as a starting point to expand onto the estimation of optimal transport plans and maps in Section~\ref{StoPlanAndMapEst}. References to a number of applications in theoretical and applied mathematics will be provided at the end. The Appendix will state further useful theorems, the proofs of which can be found in the accompanying references.