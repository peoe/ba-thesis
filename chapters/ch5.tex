\chapter*{Outlook}
\phantomsection{}
\addcontentsline{toc}{chapter}{Outlook}

In this thesis we have seen how estimations of large-scale optimal transport plans and maps can be obtained. The latter can directly be employed in applications of the theory of optimal transport, while the prior may serve as a basis for further development. When considering optimal transport problems only on a small scale, the Sinkhorn iteration may be improved to near-linear time, as shown by~\cite{Alts2019}.

Several areas of application are given in~\cite{San2015}. In Section~1.7.1 and\ \cite{Seg2018} the general OT problems are seen through a probabilistic lens. Integrals are interpreted as expectations, the starting measures $\mu$ and $\nu$ are used to describe distributions of random variables, and the obtained plan or map are viewed as a joint distribution or transformation between both variables respectively. When considering application in statistical mathematics, Section~2.5.1 suggests an approach to histogram equalization. Off of the motivation of the original Monge Problem, an interpretation in logistical or economical terms is articulated in Section~1.7.3. The logistical point of view is further developed in Section~4.4.1 including traffic equilibria and numerical solutions to continuous transportation problems. An extension to branched transport on graphs and relaxed continuous models is made in Section~4.4.2. Combining the previous two ideas suggests applications in stochastic finance. Section~1.7.5 in particular shows how to extend into martingale optimal transport problems, which may be applied in the theory of hedging financial assets. An approach to apply optimal transport in generative adversarial networks is shown in~\cite{Sal2018}. Improvements in the fairness of statistical learning by using optimal transport have been shown by~\cite{Barr2018}. Further foundations for application in computer science can be found in~\cite{Levy2017}. More algorithmic and heuristic approaches can be found in~\cite{Pey2019}, a solution to auctions via optimal transport in particular may be found in Section~3.7. Optimal transport also finds use in image processing, an overview can be found in~\cite{Papa2015}; particular applications like identity swapping in images with large discrepencies and image segmentation can be found in~\cite{Zhu2020} and~\cite{Rabin2015} respectively.

Optimal transport may also be used in more theoretical contexts. Using the \textit{Wasserstein distances} between measures allows for the conjunction of optimal transport and Sobolev spaces, as outlined in~\cite{San2015}, Section~5.5.2 and 8.4. This allows for an extension to gradient flows and partial differential equations in general. In Chapter~5 Wasserstein distances are combined with a subset of the space of probability measures to obtain \textit{Wasserstein spaces}. The topology induced by the Wasserstein distance on these spaces are then used to gain insight into constant-speed geodesics on Wasserstein spaces. A more detailed explanation on gradient flows including sections on optimal transport can be found in~\cite{Ambr2005}.

\todoinline{TODO:~add final closing sentence/phrase}